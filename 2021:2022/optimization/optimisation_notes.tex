\documentclass[12pt]{report}
\usepackage[thinc]{esdiff} % for typesettign derivatives
\usepackage{amsthm} % provides an enhanced version of LaTex's \newtheorem command
\usepackage{mdframed} % framed environments that can split at page boundaries
\usepackage{enumitem} % bulletin points or other means of listing things
\usepackage{amssymb} % for AMS symbols
\usepackage{amsmath} % so as to use align
\usepackage{latexsym} % so as to use symbols like \leadsto
\usepackage{mathrsfs} % for using mathscr for char like operators
\usepackage{commath} % for using norm symbol
\usepackage{mathtools} % for using environments like dcases
\usepackage{authblk} % for writing affiliations
\usepackage{graphicx} % for importing images
\graphicspath{{./images/}} % for the path to images, also always put label behind captions
\usepackage{textcomp} % for using degree symbol
\usepackage{hyperref} % for clickable link in the pdf & customizable reference text
\usepackage[all]{hypcap} % for clickable link to images instead of caption
\usepackage[margin=1.0in]{geometry} % default is 1.5in
% \usepackage[left=0.4in, right=0.4in, top=0.8in, bottom=0.8in]{geometry}
\usepackage[title]{appendix} % for attaching appendix
\allowdisplaybreaks % allow page breaking in display maths, like align
\usepackage{xcolor} % for setting color of a block of text, use \textcolor{<color>}{}
\usepackage[normalem]{ulem} % for strikethrough text, use \sout{}
% allow for more advanced table layout
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{siunitx}
% for adjusting caption settings
\usepackage{caption}
\captionsetup[table]{skip=10pt}

\theoremstyle{definition}
\mdfdefinestyle{defEnv}{%
  hidealllines=false,
  nobreak=true,
  innertopmargin=-1ex,
}

% The following is for writing block of code
\usepackage{listings}
\usepackage{color}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

% setting of the thickness of the 4 lines of box
\setlength{\fboxrule}{2pt}

% Use the following to change code language and related settings
\lstset{frame=tb,
  language=Python,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3,
  literate={~} {$\sim$}{1}
}

\pagestyle{headings}
\author{Lectured by Dr Dante Kalise}
\title{Optimization}
\affil{Typed by Aris Zhu Yi Qing}
\begin{document}
\maketitle
\tableofcontents

\chapter{Mathematical Preliminaries}

\section{Topological Concepts}

\newmdtheoremenv[style=defEnv]{theorem}{Definition}
\begin{theorem}
    The \textbf{open ball} with center $c\in\mathbb{R}^{n}$ and radius $r$ is
    \[
        B(c,r)=\left\{\mathbf{x}:\norm{\mathbf{x}-c}<r\right\}.
    \]
    Similarly, the \textbf{closed ball} with center $c$ and radius $r$ is
    \[
        B[c,r]=\left\{\mathbf{x}:\norm{\mathbf{x}-c}\le r\right\}.
    \]
\end{theorem}

\newmdtheoremenv[style=defEnv]{interior point}[theorem]{Definition}
\begin{interior point}
    Given a set $U\subseteq\mathbb{R}^{n}$, a point $\mathbf{c}\in U$ is called an
    \textbf{interior point} of $U$ if $\exists r>0$ for which
    $B(\mathbf{c},r)\subseteq U$. The set of all interior points of a given set
    $U$ is called the interior of the set and is denoted by
    \[
        \text{int}(U)=\left\{\mathbf{x}\in U:B(\mathbf{x},r)\subseteq U\text{
        for some }r>0\right\}.
    \]
\end{interior point}

\newmdtheoremenv[style=defEnv]{boundary points}[theorem]{Definition}
\begin{boundary points}
    Given a set $U\subseteq\mathbb{R}^{n}$, a \textbf{boundary point} of $U$ is
    a vector $\mathbf{x}\in\mathbb{R}^{n}$ satisfying that any neighbourhood of $\mathbf{x}$
    contains at least one point in $U$ and at least one point in its
    completement $U^{c}$. 
    We denote
    \[
        \text{bd}(U) = \text{The set of all boundary points of a set $U$}.
    \]
\end{boundary points}

\newmdtheoremenv[style=defEnv]{closure}[theorem]{Definition}
\begin{closure}
    The \textbf{closure} of a set $U\subseteq\mathbb{R}^{n}$ is 
    the smallest closed set containing $U$,
    denoted by cl$(U)$ with
    \[
        \text{cl}(U)=U\cup\text{bd}(U).
    \]
\end{closure}

\newmdtheoremenv[style=defEnv]{boundedness}[theorem]{Definition}
\begin{boundedness}
    A set $U\subseteq\mathbb{R}^{n}$ is called \textbf{bounded}
    if $\exists M>0$ for which $U\subseteq B(0,M)$.
\end{boundedness}

\newmdtheoremenv[style=defEnv]{compactness}[theorem]{Definition}
\begin{compactness}
    A set $U\subseteq\mathbb{R}^{n}$ is called \textbf{compact}
    if it is closed and bounded.
\end{compactness}

\section{Multi-variable Calculus}

\newmdtheoremenv[style=defEnv]{directional derivative}[theorem]{Definition}
\begin{directional derivative}
    The \textbf{directional derivative} of a scalar function $f$ w.r.t.
    $\mathbf{d}$ at a point $\mathbf{x}$ is denoted as
    \[
        f'(\mathbf{x};\mathbf{d})=\nabla f(\mathbf{x})^T\mathbf{d}
    \]
\end{directional derivative}


\newmdtheoremenv[style=defEnv]{gradient and hessian of quadratic functions}[theorem]{Theorem}
\begin{gradient and hessian of quadratic functions}
    Given the general quadratic functions of the form
    \[
        f(\mathbf{w})=\mathbf{w}^TA\mathbf{w}+\mathbf{b}^T\mathbf{w}+\gamma
    \]
    we have
    \[
        \nabla f(\mathbf{w})=(A^T+A)\mathbf{w}+\mathbf{b},
        \qquad
        \nabla^2 f(\mathbf{w})=A+A^T.
    \]
    If $A$ is symmetric, then
    \[
        \nabla f(\mathbf{w})=2A\mathbf{w}+\mathbf{b},
        \qquad
        \nabla^2 f(\mathbf{w})=2A.
    \]
\end{gradient and hessian of quadratic functions}

\section{Positive Definiteness of Matrix}

\newmdtheoremenv[style=defEnv]{diagonal elem positive}[theorem]{Proposition}
\begin{diagonal elem positive}
    Let $A$ be a positive definite (semidefinite) matrix, then 
    \begin{itemize}
        \item the diagonal elements of $A$ are positive (nonnegative)
        \item Tr($A$) and det($A$) are positive (nonnegative)
    \end{itemize} 
\end{diagonal elem positive}

\newmdtheoremenv[style=defEnv]{eigenvalue characterization}[theorem]{(Test 1) Theorem}
\begin{eigenvalue characterization}
    Let $A\in\mathbb{R}^{n\times n}$ be symmetric, then
    \begin{itemize}
        \item $A$ is positive definite (semidefinite) iff all its eigenvalues
            are positive (nonnegative).
        \item $A$ is indefinte iff it has at least one positive eigenvalue and
            at least one negative eigenvalue.
    \end{itemize} 
\end{eigenvalue characterization}

\newmdtheoremenv[style=defEnv]{diagonal dominance}[theorem]{Definition}
\begin{diagonal dominance}
    Let $A\in\mathbb{R}^{n\times n}$ be symmetric, then
    \begin{itemize}
        \item $A$ is \textbf{diagonally dominant} if
            \[
                |A_{ii}| \ge \sum_{j\neq i}|A_{ij}|\quad\forall i=1,2,\ldots,n
            \]
        \item $A$ is \textbf{strictly diagonally dominant} if
            \[
                |A_{ii}|>\sum_{j\neq i}|A_{ij}|\quad\forall i=1,2,\ldots,n
            \]
    \end{itemize} 
\end{diagonal dominance}

\newmdtheoremenv[style=defEnv]{positive definiteness of diagonally dominant matrices}[theorem]{(Test 2) Theorem}
\begin{positive definiteness of diagonally dominant matrices}
    If $A\in\mathbb{R}^{n\times n}$ is symmetric, diagonally dominant with
    positive (nonnegative) diagonal elements, then $A$ is positive definite
    (semidefinite).
\end{positive definiteness of diagonally dominant matrices}





\chapter{Unconstrained Optimization}

\section{Optimums}

\newmdtheoremenv[style=defEnv]{global optimum}[theorem]{Definition}
\begin{global optimum}
    Let $f:S\rightarrow\mathbb{R}$ be defined on a set
    $S\subseteq\mathbb{R}^{n}$, then $\forall \mathbf{x}\in S$,
    \[
        \mathbf{x}^* \in S \text{ is a \textbf{global minimum} point of $f$ over
        $S$ if $f(\mathbf{x})\ge f(\mathbf{x}^*)$},
    \]
    \[
        \mathbf{x}^* \in S \text{ is a \textbf{strict global minimum} point of $f$ over
        $S$ if $f(\mathbf{x})> f(\mathbf{x}^*)$},
    \]
    and similar definitions for maximum.
\end{global optimum}

\newmdtheoremenv[style=defEnv]{local optimum}[theorem]{Definition}
\begin{local optimum}
    Let $f:S\rightarrow\mathbb{R}$ be defined on a set
    $S\subseteq\mathbb{R}^{n}$, $\mathbf{x}^*\in S$ 
    is a \textbf{local minimum} of $f$ over $S$ if
    $\exists r>0$ s.t. $f(\mathbf{x}^*)\le f(\mathbf{x})$ 
    for any $\mathbf{x}\in S\cap B(\mathbf{x}^*,r)$.
    Similar definitions for \textbf{strict local minimum} and maximum.
\end{local optimum}

\newmdtheoremenv[style=defEnv]{stationary points}[theorem]{Definition}
\begin{stationary points}
    Let $f:U\rightarrow\mathbb{R}$ be a function defined on a set
    $U\subseteq\mathbb{R}^{n}$.
    Suppose that $\mathbf{x}^*\in\text{int}(U)$ and that all the partial
    derivatives of $f$ are defined at $\mathbf{x}^*$, then $\mathbf{x}^*$ is
    called a \textbf{stationary point} of $f$ if $\nabla f(\mathbf{x}^*)=0$.
\end{stationary points}

\section{Second-order Optimality Conditions}

\newmdtheoremenv[style=defEnv]{second-order optimality conditions}[theorem]{Theorem}
\begin{second-order optimality conditions}
    Let $f:U\rightarrow\mathbb{R}$ be a function defined on an open set
    $U\subseteq\mathbb{R}^{n}$. Suppose that $f$ is twice continuously
    differentiable over $U$ and that $\mathbf{x}^*$ is a stationary point, then
    \begin{itemize}
        \item $\mathbf{x}^*$ is a local minimum point $\iff$
            $\nabla^2f(\mathbf{x}^*)\succeq 0$.
        \item $\mathbf{x}^*$ is a strict local minimum point $\iff$
            $\nabla^2f(\mathbf{x}^*)\succ 0$.
        \item similar necessary and sufficient conditions for (strict) local
            maximum point
    \end{itemize} 
\end{second-order optimality conditions}

\newmdtheoremenv[style=defEnv]{saddle points}[theorem]{Definition}
\begin{saddle points}
    Let $f:U\rightarrow\mathbb{R}$ be a continuously differentiable function
    defined on an open set $U\subseteq\mathbb{R}^{n}$. A stationary point 
    $\mathbf{x}^*\in U$ is called a \textbf{saddle point} of $f$ over $U$ if it
    is neither a local minimum nor a local maximum point of $f$ over $U$.
\end{saddle points}

\newmdtheoremenv[style=defEnv]{sufficient condition for saddle points}[theorem]{Theorem}
\begin{sufficient condition for saddle points}
    Let $f:U\rightarrow\mathbb{R}$ be a continuously differentiable function
    defined on an open set $U\subseteq\mathbb{R}^{n}$. 
    Suppose that $f$ is twice continuously differentiable over $U$ and that
    $\mathbf{x}^*$ is a stationary point. Then
    \[
        \nabla^2 f(\mathbf{x}^*) \text{ is an indefinite matrix} \Longrightarrow \mathbf{x}^*
        \text{ is a saddle point of $f$ over $U$}.
    \]
\end{sufficient condition for saddle points}

\section{Attainment of Minimal/Maximal Points}

\newmdtheoremenv[style=defEnv]{Weierstrass' Theorem}[theorem]{(Weierstrass') Theorem}
\begin{Weierstrass' Theorem}
    Let $f$ be a continuous function defined over a nonempty conpact set
    $C\subseteq\mathbb{R}^{n}$. Then $\exists$ a global minimum point of $f$
    over $C$ and a global maximum point of $f$ over $C$.
\end{Weierstrass' Theorem}

\newmdtheoremenv[style=defEnv]{coerciveness}[theorem]{Definition}
\begin{coerciveness}
    Let $f:\mathbb{R}^{n}\rightarrow\mathbb{R}$ be a continuous function over
    $\mathbb{R}^{n}$. $f$ is called \textbf{coercive} if
    \[
        \underset{\norm{\mathbf{x}}\rightarrow\infty}{\lim}f(\mathbf{x})=\infty
    \]
\end{coerciveness}

\newmdtheoremenv[style=defEnv]{attainment of global optima}[theorem]{Theorem}
\begin{attainment of global optima}
    Let $f:\mathbb{R}^{n}\rightarrow\mathbb{R}$ be a continuous and coercive function
    and let $S\subseteq\mathbb{R}^{n}$ be a nonempty closed set. Then $f$
    attains a global minimum point on $S$.
\end{attainment of global optima}


\section{Global Optimality Conditions}

\newmdtheoremenv[style=defEnv]{global optimality condition}[theorem]{Theorem}
\begin{global optimality condition}
    Let $f$ be a twice continuously differentiable function defined over
    $\mathbb{R}^{n}$.
    Let $\mathbf{x}^*\in\mathbb{R}^{n}$ be a
    stationary point of $f$. Then
    \[
        \nabla^2 f(\mathbf{x})\succeq 0\;\forall \mathbf{x}\in\mathbb{R}^{n}
        \Longrightarrow
        \mathbf{x}^* \text{ is a global minimum point of $f$}.
    \]
\end{global optimality condition}

\newmdtheoremenv[style=defEnv]{quadratic function optimality}[theorem]{Proposition}
\begin{quadratic function optimality}
    Let $f(\mathbf{x})=\mathbf{x}^TA\mathbf{x}+2\mathbf{b}^T\mathbf{x}+c$, with
    $A\in\mathbb{R}^{n\times n}$ symmetric, then
    \begin{enumerate}
        \item $\mathbf{x}$ is a stationary point of $f$ iff
            $A\mathbf{x}=-\mathbf{b}$.
        \item if $A\succeq 0$, then $\mathbf{x}$ is a global minimum point of
            $f$ iff $A\mathbf{x}=-\mathbf{b}$.
        \item if $A\succ 0$, then $\mathbf{x}=-A^{-1}\mathbf{b}$ is a strict
            global minimum point of $f$.
    \end{enumerate} 
\end{quadratic function optimality}


\chapter{Linear Least Squares}

\section{Problem Formulation}

Consider the linear system
\[
    S\mathbf{x}\approx\mathbf{b},\quad(S\in\mathbb{R}^{m\times
    n},\mathbf{b}\in\mathbb{R}^{m},m>n)
\]
To solve the above system, the usual approach is to transform it to become
\[
    \underset{\mathbf{x}}{\text{min}}\norm{S\mathbf{x}-\mathbf{b}}^2
    \iff
    \underset{\mathbf{x}\in\mathbb{R}^{n}}{\text{min}}
    \left\{f(\mathbf{x})\equiv
    \mathbf{x}^TS^TS\mathbf{x}-2\mathbf{b}^TS\mathbf{x}+\norm{\mathbf{b}}^2\right\}.
\]
Note that $\nabla^2f(\mathbf{x})=2S^TS\succeq 0$ since
$\mathbf{x}^TS^TS\mathbf{x}=(S\mathbf{x})^T(S\mathbf{x})=\norm{S\mathbf{x}}^2\ge 0$.
Therefore, the unique optimal solution $\mathbf{x}_\text{LS}$ is the solution
$\nabla f(\mathbf{x})=0$, namely
\[
    (S^TS)\mathbf{x}_\text{LS}=S^T\mathbf{b} \Longrightarrow
    \mathbf{x}_\text{LS}={(S^TS)}^{-1}S^T\mathbf{b}.
\]

\section{Data Fitting}

\begin{enumerate}
    \item For dataset $(\mathbf{s}_i,b_i)$ where $\mathbf{s}_i\in\mathbb{R}^{n}$ 
        and $b_i\in\mathbb{R}$, we could transform to problem
        \[
            \underset{\mathbf{x}}{\text{min}}
            \sum_{i=1}^{m} {(\mathbf{s}_i^T\mathbf{x}-b_i)}^{2}
            \Longrightarrow
            \underset{\mathbf{x}}{\text{min}}
            \norm{S\mathbf{x}-\mathbf{b}}^2
        \]
    \item For polynomial fitting, given a set of points $\mathbb{R}^{2}:(u_i,y_i)$,
        the associated linear system is
        \[
            \begin{pmatrix}
                1 & u_1 & u_1^2 & \cdots & u_1^d \\
                1 & u_2 & u_2^2 & \cdots & u_2^d \\
                \vdots & \vdots & \vdots & \ddots & \vdots \\
                1 & u_m & u_m^2 & \cdots & u_m^d \\
            \end{pmatrix} 
            \begin{pmatrix}
                a_0 \\
                a_1 \\
                \vdots \\
                a_d
            \end{pmatrix} 
            =
            \begin{pmatrix}
                y_0 \\
                y_1 \\
                \vdots \\
                y_m
            \end{pmatrix} 
        \]
\end{enumerate} 

\section{Regularized Least Squares}

A Regularized Least Square problem is formulated as
\[
    \underset{\mathbf{x}}{\text{min}}
    \norm{S\mathbf{x}-\mathbf{b}}^2
    +\lambda R(\mathbf{x}),
\]
where $\lambda$ is the regularization parameter and $R(\cdot)$ is the
regularization function (also called a \emph{penalty} function).
A common choice is a quadratic regularization function:
\[
    \underset{\mathbf{x}}{\text{min}}
    \norm{S\mathbf{x}-\mathbf{b}}^2
    +\lambda \norm{D\mathbf{x}}^2
\]
with its optimal solution being
\[
    \mathbf{x}_\text{RLS}={(S^TS+\lambda D^TD)}^{-1}S^T \mathbf{b}
\]
since $\nabla f=2S^TS\mathbf{x}-2S^T \mathbf{b}+2\lambda D^TD\mathbf{x}=0$.

\section{Denoising}

Suppose a noisy measurement of a signal $\mathbf{x}\in\mathbb{R}^{n}$ is given
\[
    \mathbf{b}=\mathbf{x}+\mathbf{w}
\]
where $\mathbf{x}$ is the ``true'' unknown signal, $\mathbf{w}$ is the unknown
noise and $\mathbf{b}$ is the (known) measures vector.
We could define
\[
    R(\mathbf{x})=\norm{L\mathbf{x}}^2, \text{ where }
    L=
    \begin{pmatrix}
        1 & -1 & 0 & 0 & \cdots & 0 & 0 \\
        0 & 1 & -1 & 0 & \cdots & 0 & 0 \\
        0 & 0 & 1 & -1 & \cdots & 0 & 0 \\
        \vdots & \vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
        0 & 0 & 0 & 0 & \cdots & 1 & -1
    \end{pmatrix} 
\]
as the regularization function to penalize any sudden variations in signal. The
RLS is thus
\[
    \underset{\mathbf{x}}{\text{min}}
    \norm{\mathbf{x}-\mathbf{b}}^2
    +\lambda\norm{L\mathbf{x}}^2
\]
with its direct solution being
\[
    \mathbf{x}_\text{RLS}(\lambda)={(I+\lambda L^TL)}^{-1}\mathbf{b}.
\]


\chapter{The Gradient Method}

\section{Descent Direction}

\newmdtheoremenv[style=defEnv]{descent direction}[theorem]{Definition}
\begin{descent direction}
    Let $f:\mathbb{R}^{n}\rightarrow\mathbb{R}$ be a continuously differentiable function.
    A vector $\mathbf{0}\neq\mathbf{d}\in\mathbb{R}^{n}$ is called a
    \textbf{descent direction} of $f$ at $\mathbf{x}$ if
    \[
        f'(\mathbf{x};\mathbf{d})=\nabla f(\mathbf{x})^T\mathbf{d}<0.
    \]
\end{descent direction}

\newtheorem{descent direction example}[theorem]{Example}
\begin{descent direction example}
    The descent direction can be $\mathbf{d}=-\nabla f(\mathbf{x})$,
    since as long as $\nabla f(\mathbf{x})\neq 0$ 
    ($\mathbf{x}$ is a non-stationary point), we have
    \[
        f'(\mathbf{x};-\nabla f(\mathbf{x}))=-\nabla f(\mathbf{x})^Tf(\mathbf{x})
        =-\norm{\nabla f(\mathbf{x})}^2 < 0.
    \]
\end{descent direction example}

\newmdtheoremenv[style=defEnv]{descent property}[theorem]{Lemma}
\begin{descent property}
    Let $f:\mathbb{R}^{n}\rightarrow\mathbb{R}$ be a continuously differentiable function.
    Let $\mathbf{x}\in\mathbb{R}^{n}$. 
    Suppose that $\mathbf{d}$ is a descent direction of $f$ at $\mathbf{x}$,
    then
    \[
        \exists\epsilon>0\text{ s.t. }\forall
        t\in(0,\epsilon],f(\mathbf{x}+t\mathbf{d})<f(\mathbf{x}).
    \]
\end{descent property}

\newmdtheoremenv[style=defEnv]{descent optimal direction}[theorem]{Lemma}
\begin{descent optimal direction}
    Let $f$ be a continuously differentiable function and
    $\mathbf{x}\in\mathbb{R}^{n}$ be a non-stationary point ($\nabla
    f(\mathbf{x})\neq 0$), then the optimal solution of
    \[
        \underset{\mathbf{d}}{\text{min}}\left\{f'(\mathbf{x};\mathbf{d}:\norm{\mathbf{d}}=1\right\}
    \]
    is $\mathbf{d}=-\frac{\nabla f(\mathbf{x})}{\norm{\nabla f(\mathbf{x})}}$.
\end{descent optimal direction}

\newmdtheoremenv[style=defEnv]{zig-zag effect}[theorem]{Lemma}
\begin{zig-zag effect}
    Let ${\left\{\mathbf{x}^k\right\}}_{k>0}$ be the sequence generated by the
    gradient descent method with \emph{exact} line search for solving a problem
    of minimizing a continuously differentiable function $f$. Then $\forall
    k=0,1,2,\ldots$,
    \[
        {(\mathbf{x}^{k+2}-\mathbf{x}^{k+1})}^{T}
        (\mathbf{x}^{k+1}-\mathbf{x}^k)=0.
    \]
\end{zig-zag effect}


\section{Stepsize Selection Rules}

Finding the right $t^k\in\mathbb{R}^{n}$, called the \textbf{stepsize}, is
referred in the literature as \textbf{line search}.

\begin{enumerate}
    \item Constant stepsize: $t^k=\overline{t}$ $\forall k$.
    \item Exact stepsize: $t^{k}$ is a minimizer of $f$ along the ray
        $\mathbf{x}^{k}_t\mathbf{d}^{k}$:
        \[
            t^{k}\in \underset{t\ge
            0}{\text{argmin}}f(\mathbf{x}^{k}+t\mathbf{d}^{k})
        \]
    \item Backtracking (Armijo rule): let $s>0,\alpha\in(0,1),\beta\in(0,1)$,
        and initial stepsize $t^k=s$, while
        \[
            f(\mathbf{x}^k)-f(\mathbf{x}^k+t^k\mathbf{d}^k)<-\alpha t^k\nabla
            f(\mathbf{x}^k)^T\mathbf{d}^k
        \]
        set $t^k:=\beta t^k$, iterating until achieving the \textbf{sufficient
        decrease property}
        \[
            f(\mathbf{x}^k)-f(\mathbf{x}^k+t^k\mathbf{d}^k)\ge -\alpha t^k\nabla
            f(\mathbf{x}^k)^T\mathbf{d}^k.
        \]
\end{enumerate} 

\section{Convergence}

\newmdtheoremenv[style=defEnv]{lipschitz gradient}[theorem]{Definition}
\begin{lipschitz gradient}
    Let $f$ be a continuously differentiable function over $\mathbb{R}^{n}$.
    We say that $f$ has a \textbf{Lipschitz gradient} if
    \[
        \exists L\ge 0\text{ s.t.
        }\forall\mathbf{x},\mathbf{y}\in\mathbb{R}^{n},\;
        \norm{\nabla f(\mathbf{x})-\nabla f(\mathbf{y})}\le
        L\norm{\mathbf{x}-\mathbf{y}}.
    \]
    $L$ is called the \textbf{Lipschitz constant}.
\end{lipschitz gradient}

\underline{\textbf{Comments}}:
\begin{itemize}
    \item The class of functions with Lipschitz gradient with constant $L$ 
        is denoted as $C_L^{1,1}(\mathbb{R}^{n})$ or just $C_L^{1,1}$.
        When $L$ is irrelevant, we simply denote the class by $C^{1,1}$.
    \item If $\nabla f$ is Lipschitz with constant $L$, then it is also
        Lipschitz with constant $L'$ $\forall L'\ge L$.
    \item \underline{Linear functions}: Given $a\in\mathbb{R}^{n}$, the function
        $f(\mathbf{x})=a^T\mathbf{x}$ is in $C_0^{1,1}$.
    \item \underline{Quadratic functions}: Let $A\in\mathbb{R}^{n\times n}$,
        $\mathbf{b}\in\mathbb{R}^{n}$, and $c\in\mathbb{R}$, then the function
        $f(\mathbf{x})=\mathbf{x}^TA\mathbf{x}+2\mathbf{b}^T\mathbf{x}+c$ is
        $C_{2\;\norm{A}_2}^{1,1}$.
\end{itemize} 

\newmdtheoremenv[style=defEnv]{equivalence to boundedness of hessian}[theorem]{Theorem}
\begin{equivalence to boundedness of hessian}
    Let $f$ be a continuously differentiable function over $\mathbb{R}^{n}$.
    Then
    \[
        f\in C_L^{1,1}(\mathbb{R}^{n})
        \iff
        \norm{\nabla^2f(\mathbf{x})}\le L\;\forall \mathbf{x}\in\mathbb{R}^{n}.
    \]
\end{equivalence to boundedness of hessian}

\newmdtheoremenv[style=defEnv]{sufficient decrease of gradient method}[theorem]
{(Sufficient decrease of the gradient method) Lemma}
\begin{sufficient decrease of gradient method}
    Let $f\in C_L^{1,1}(\mathbb{R}^{n})$.
    Let ${\{\mathbf{x}^k\}}_{k\ge 0}$ be the sequence generated by the gradient
    method for solving 
    \[
        \underset{\mathbf{x}\in\mathbb{R}^{n}}{\min}f(\mathbf{x})
    \]
    with one of the following stepsize strategies:
    \begin{itemize}
        \item constant stepsize $\overline{t}\in\left(0,\frac{2}{L}\right)$,
        \item exact line search
        \item backtracking procedure with parameters $s\in\mathbb{R}_{++}$,
            $\alpha\in(0,1)$, and $\beta\in(0,1)$,
    \end{itemize} 
    then
    \[
        f(\mathbf{x}^k)-f(\mathbf{x}^{k+1})\ge M\norm{\nabla f(\mathbf{x}^k)}^2
    \]
    where
    \[
        M=
        \begin{cases}
            \overline{t}\left(1-\frac{\overline{t}L}{2}\right) & \text{constant stepsize} \\
            \frac{1}{2L} & \text{exact line search} \\
            \alpha\min{\left\{s,\frac{2(1-\alpha)\beta}{L}\right\}} & \text{backtracking}
        \end{cases} 
    \]
\end{sufficient decrease of gradient method}

\newmdtheoremenv[style=defEnv]{convergence of the gradient method}[theorem]
{(Convergence of the gradient method) Theorem}
\begin{convergence of the gradient method}
    Let $f\in C_L^{1,1}(\mathbb{R}^{n})$ and is bounded below over
    $\mathbb{R}^{n}$.
    Let ${\{\mathbf{x}^k\}}_{k\ge 0}$ be the sequence generated by the gradient
    method for solving 
    \[
        \underset{\mathbf{x}\in\mathbb{R}^{n}}{\min}f(\mathbf{x})
    \]
    with one of the following stepsize strategies:
    \begin{itemize}
        \item constant stepsize $\overline{t}\in\left(0,\frac{2}{L}\right)$,
        \item exact line search
        \item backtracking procedure with parameters $s\in\mathbb{R}_{++}$,
            $\alpha\in(0,1)$, and $\beta\in(0,1)$,
    \end{itemize} 
    then
    \begin{enumerate}
        \item $\forall k, f(\mathbf{x}^{k+1})<f(\mathbf{x}^k)$ unless $\nabla
            f(\mathbf{x}^k)=0$.
        \item $\nabla f(\mathbf{x}^k)\rightarrow 0$ as $k\rightarrow\infty$.
    \end{enumerate} 
\end{convergence of the gradient method}

\section{Condition Number and Convergence for Quadratic Function}

\newmdtheoremenv[style=defEnv]{condition number}[theorem]{Definition}
\begin{condition number}
    Let $A\in\mathbb{R}^{n\times n}$ be positive definite, Then the
    \textbf{condition number} of $A$ is
    \[
        \kappa(A)=\frac{\lambda_\text{max}(A)}{\lambda_\text{min}(A)}
    \]
    where $\lambda_\text{max}(A)$ and $\lambda_\text{min}(A)$ are the largest
    and smallest eigenvalues respectively.
\end{condition number}

\newmdtheoremenv[style=defEnv]{kantorovich inequality}[theorem]{(Kantorovich inequality)Lemma}
\begin{kantorovich inequality}
    Let $A\in\mathbb{R}^{n\times n}$ be positive definite. Then
    \[
        \forall \mathbf{0}\neq\mathbf{x}\in\mathbb{R}^{n},\;
        \frac{{(\mathbf{x}^T\mathbf{x})}^{2}}{(\mathbf{x}^TA\mathbf{x})(\mathbf{x}^TA^{-1}\mathbf{x})}
        \ge\frac{4\lambda_\text{max}(A)\lambda_\text{min}(A)}{{(\lambda_\text{max}(A)+\lambda_\text{min}(A))}^{2}}.
    \]
\end{kantorovich inequality}

\newmdtheoremenv[style=defEnv]{gradient method for minimizing quadratic function}[theorem]
{(Convergence for quadratic function) Theorem}
\begin{gradient method for minimizing quadratic function}
    Let ${\{\mathbf{x}^k\}}_{k\ge 0}$ be the sequence generated by the gradient
    method for solving 
    \[
        \underset{\mathbf{x}\in\mathbb{R}^{n}}{\min}f(\mathbf{x}^TA\mathbf{x})\quad
        (A\succ 0),
    \]
    then $\forall k=0,1,\ldots,$
    \[
        f(\mathbf{x}^{k+1})\le{\left(\frac{\lambda_\text{max}(A)-\lambda_\text{min}(A)}
        {\lambda_\text{max}(A)+\lambda_\text{min}(A)}\right)}^{2}f(\mathbf{x}^k)
        ={\left(\frac{\kappa(A)-1}{\kappa(A)+1}\right)}^{2}f(\mathbf{x}^k).
    \]
\end{gradient method for minimizing quadratic function}

\section{Scaled Gradient Method}

A way to mitigate the slow convergence due to poor conditioning of the Hessian
is to formulate a rescaled version of the problem. From the minimization problem
\[
    \min\left\{f(\mathbf{x}):\mathbf{x}\in\mathbb{R}^{n}\right\}
\]
we introduce a nonsingular matrix $S\in\mathbb{R}^{n\times n}$ to make the
linear change of variables $\mathbf{x}=S\mathbf{y}$ and obtain the equivalent
problem
\[
    \min\left\{g(\mathbf{y})\equiv f(S\mathbf{y}):\mathbf{y}\in\mathbb{R}^{n}\right\}
\]
Since $\nabla g(\mathbf{y})=S^T\nabla f(S\mathbf{y})=S^T\nabla f(\mathbf{x})$,
the gradient method for the rescaled problem reads
\[
    \mathbf{y}^{k+1}=\mathbf{y}^{k}-t^kS^T\nabla f(S\mathbf{y}^k).
\]
Multiplying both sides by $S$, with $\mathbf{x}^k=S\mathbf{y}^k$, and define
$D=SS^T$, we have
\[
    \mathbf{x}^{k+1}=\mathbf{x}^{k}-t^kD\nabla f(\mathbf{x}^k).
\]
Since $D\succ 0$, so
\[
    f'(\mathbf{x}^k;-D\nabla f(\mathbf{x}^k))=-\nabla f(\mathbf{x}^k)^TD\nabla
    f(\mathbf{x}^k)<0.
\]
A well-known choice for $D^k$ is to pick $D^k={(\nabla^2f(\mathbf{x}^k))}^{-1}$
(Newton's method). Another alternative is to use a diagonal scaling, e.g.
\[
    {\left(D^k\right)}_{ii}={\left(\frac{\partial^2f(\mathbf{x}^k)}{\partial
    x_i^2}\right)}^{-1}
\]

\section{The Kaczmarz Algorithm}

The \emph{Kaczmarz Algorithm} solves the linear system
\[
    A\mathbf{x}=\mathbf{b}
\]
by iterating projections along the $i$-th row of the matrix $A$, denoted by
$\mathbf{a}_i^T$:
\[
    \mathbf{x}^{k+1}=\mathbf{x}^k+\frac{b_i-\mathbf{a}_i^T\mathbf{x}^k}{\norm{\mathbf{a}_i}^2}\mathbf{a}_i
\]
In the original Kaczmarz algorithm, the $i$-th row is chosen periodically by
cycling through all rows. If chooses $i$-th row randomly, we can show that the
algorithm converges exponentially, and this is known as \emph{randomized Kaczmarz Algorithm}.

\medskip\noindent
The algorithm works because the problem of solving the linear system 
$A\mathbf{x}=\mathbf{b}$ could be formulated 
as an optimization problem
\[
    \underset{\mathbf{x}}{\text{min}}\frac{1}{2m}\norm{A\mathbf{x}-\mathbf{b}}^2
    =\frac{1}{2m}\sum_{i=1}^{m} {(\mathbf{a}_i^T\mathbf{x}-\mathbf{b}_i)}^{2}
\]
for which the gradient descent method could be constructed as
\[
    \mathbf{x}^{k+1}=\mathbf{x}^k-\frac{t}{m}A^T(A\mathbf{x}-\mathbf{b})
\]
but the problem could also be formulated as
\[
    \underset{\mathbf{x}}{\text{min}}\frac{1}{2m}\norm{A\mathbf{x}-\mathbf{b}}^2
    =\frac{1}{2m}\sum_{i=1}^{m} {(\mathbf{a}_i^T\mathbf{x}-b_i)}^{2}
    =\frac{1}{2}\mathbb{E}_i[\mathbf{a}_i^T\mathbf{x}-b_i],
\]
which can then be translated to the action of randomly picking a row of $A$,
becoming
\[
    \mathbf{x}^{k+1}=\mathbf{x}^k-\frac{t}{m}(\mathbf{a}_i^T\mathbf{x}-b_i)\mathbf{a}_i
\]

\section{Stochastic Gradient Descent}

\newmdtheoremenv[style=defEnv]{convergence of SGD}[theorem]{Theorem}
\begin{convergence of SGD}
    Assuming that
    \begin{itemize}
        \item The cost $g(\mathbf{x})$ is such that
            \[
                \norm{\nabla g(\mathbf{x})-\nabla g(\mathbf{y})}\le
                L\norm{\mathbf{x}-\mathbf{y}},\quad
                \text{and}\quad
                \nabla^2g(\mathbf{x})\succeq\mu I.
            \]
        \item The sample gradient $\nabla Q_i(\mathbf{x}^k)$ is an unbiased
            estimate of $\nabla g(\mathbf{x}^k)$.
        \item \[
                \forall \mathbf{x},
                \mathbb{E}_i\left[\norm{Q_i(\mathbf{x})}^2\right]\le
                \sigma^2+c\norm{\nabla g(\mathbf{x})}^2.
        \]
    \end{itemize} 
    Then if $t^k\equiv t\le \frac{1}{Lc}$, then SGD achieves
    \[
        \mathbb{E}\left[g(\mathbf{x}^k)-g(\mathbf{x}^*)\right]
        \le\frac{tL\sigma^2}{2\mu}+{(1-t\mu)}^{k}(g(\mathbf{x}^0)-g(\mathbf{x}^*)).
    \]
\end{convergence of SGD}
\underline{\textbf{Comments}}
\begin{enumerate}
    \item Fast (linear) convergence during the first iterations.
    \item Convergence to a neighbourhood of $\mathbf{x}^*$, without further
        progress.
    \item If gradient computation is noiseless ($\sigma=0$), then linear
        convergence to optimal point.
    \item A smaller stepsize $t$ yield better converging points.
\end{enumerate} 

\newmdtheoremenv[style=defEnv]{batch gradient descent}[theorem]{Definition}
\begin{batch gradient descent}
    The \textbf{batch gradient descent} algorithm is defined as
    \[
        \mathbf{x}^{k+1}=\mathbf{x}^k-t^k\nabla g(\mathbf{x}^k)
        =\mathbf{x}^k-\frac{t^k}{|K|}\sum_{i\in K}\nabla Q_i(\mathbf{x}^k),
    \]
    where $K$ denotes a set of $p$ randomly selected datapoints.
\end{batch gradient descent}


\chapter{Convexity}

\section{Convex Sets}

\newmdtheoremenv[style=defEnv]{convex sets}[theorem]{Definition}
\begin{convex sets}
    A set $C\subseteq\mathbb{R}^{n}$ is called \textbf{convex} if
    \[
        \forall \mathbf{x},\mathbf{y}\in C\text{ and }\lambda\in[0,1],
        \lambda\mathbf{x}+(1-\lambda)\mathbf{y}\in C.
    \]
    Equivalently, for any $\mathbf{x},\mathbf{y}\in C$, the line segment
    $[\mathbf{x},\mathbf{y}]$ is also in $C$.
\end{convex sets}

\newtheorem{convex sets example}[theorem]{Example}
\begin{convex sets example}
    Very important convex sets
    \begin{itemize}
        \item A line in $\mathbb{R}^{n}$ is a set of the form
            \[
                L=\left\{\mathbf{z}+t\mathbf{d}:t\in\mathbb{R}\right\},
            \]
            where $\mathbf{z},\mathbf{d}\in\mathbb{R}^{n}$ and $\mathbf{d}\neq \mathbf{0}$.
        \item $[\mathbf{x},\mathbf{y}],(\mathbf{x},\mathbf{y})$ for
            $\mathbf{x},\mathbf{y}\in\mathbb{R}^{n}(\mathbf{x}\neq\mathbf{y})$,
            $\emptyset$, and $\mathbb{R}^{n}$.
        \item A \textbf{hyperplane} is a set of the form
            \[
                H=\left\{\mathbf{x}\in\mathbb{R}^{n}:\mathbf{a}^T\mathbf{x}=b\right\}\quad
                (\mathbf{a}\in\mathbb{R}\backslash\left\{\mathbf{0}\right\},b\in\mathbb{R})
            \]
        \item The associated \textbf{half space} is the set
            \[
                H^-=\left\{\mathbf{x}\in\mathbb{R}^{n}:\mathbf{a}^T\mathbf{x}\le b\right\}.
            \]
        \item The open ball $B(\mathbf{c},r)$ and the closed ball $B[\mathbf{c},r]$.
        \item The \textbf{ellipsoid} is a set of the form
            \[
                E=\left\{\mathbf{x}\in\mathbb{R}^{n}:\mathbf{x}^TQ\mathbf{x}+2\mathbf{b}^T\mathbf{x}+c\le 0\right\}
            \]
            where $Q\in\mathbb{R}^{n\times n}$ is positive semidefinite,
            $\mathbf{b}\in\mathbb{R}^{n}$ and $c\in\mathbb{R}$.
    \end{itemize} 
\end{convex sets example}

\newmdtheoremenv[style=defEnv]{intersection of convex sets}[theorem]{Lemma}
\begin{intersection of convex sets}
    Let $C_i\subseteq\mathbb{R}^{n}$ be a convex set for any $i\in I$, where $I$
    is an index set (possibly infinite), then $\bigcap_{i\in I}C_i$ is convex.
\end{intersection of convex sets}
\underline{\textbf{Comments}}: A direct consequence of the above is that convex
polytopes of the form
\[
    P=\left(\mathbf{x}\in\mathbb{R}^{n}:A\mathbf{x}\le\mathbf{b}\right),
\]
are convex since they are generated as the intersection of $m$ half-spaces
$\mathbf{a}_i^T\mathbf{x}\le b_i$.

\newmdtheoremenv[style=defEnv]{convex sets properties}[theorem]{Theorem}
\begin{convex sets properties}
    Several important algebraic properties of convex sets:
    \begin{enumerate}
        \item Let $C_1,C_2,\ldots,C_k\subseteq\mathbb{R}^{n}$ be convex sets and
            let $\mu_1,\mu_2,\ldots,\mu_k\in\mathbb{R}$, then the set
            $\mu_1C_1+\mu_2C_2+\cdots+\mu_kC_k$ is convex.
        \item Let $C_i\subseteq\mathbb{R}^{k_i}$, $i=1,\ldots,m$ be convex sets,
            then the cartesian product
            \[
                C_1\times C_2\times\cdots\times C_m
                =\left\{(\mathbf{x}_1,\mathbf{x}_2,\ldots,\mathbf{x}_m):\mathbf{x}_i\in
                C_i,i=1,2,\ldots,m\right\}
            \]
            is convex.
        \item Let $M\subseteq\mathbb{R}^{n}$ be a convex set and let
            $A\in\mathbb{R}^{m\times n}$, then the set
            \[
                A(M)=\left\{A\mathbf{x}:\mathbf{x}\in M\right\}
            \]
            is convex.
        \item Let $D\subseteq\mathbb{R}^{m}$ be convex and let
            $A\in\mathbb{R}^{m\times n}$, then the set
            \[
                A^{-1}(D)=\left\{\mathbf{x}\in\mathbb{R}^{n}:A\mathbf{x}\in D\right\}
            \]
            is convex.
    \end{enumerate} 
\end{convex sets properties}

\section{Convex Hull}

\newmdtheoremenv[style=defEnv]{convex combinations}[theorem]{Definition}
\begin{convex combinations}
    Given $m$ points
    $\mathbf{x}_1,\mathbf{x}_2,\ldots,\mathbf{x}_m\in\mathbb{R}^{n}$, a
    \textbf{convex combination} of these $m$ points is a vector of the form 
    \[
        \lambda_1\mathbf{x}_1+\lambda_2\mathbf{x}_2+\cdots+\lambda_m\mathbf{x}_m
    \]
    where $\lambda_i\in\mathbb{R}_+$ for $i=1,2,\ldots,m$ and satisfy
    $\sum_{i=1}^m\lambda_i=1$ ($\pmb{\lambda}\in\Delta_m$).
\end{convex combinations}

\newmdtheoremenv[style=defEnv]{convex combination is convex}[theorem]{Theorem}
\begin{convex combination is convex}
    Let $C\subseteq\mathbb{R}^{n}$ be a convex set and let $\mathbf{x}_i\in C$
    for $i=1,2,\ldots,m$. Then for any $\pmb{\lambda}\in\Delta_m$, the relation
    \[
        \sum_{i=1}^{m} \lambda_i \mathbf{x}_i\in C
    \]
    holds.
\end{convex combination is convex}


\newmdtheoremenv[style=defEnv]{convex hull}[theorem]{Definition}
\begin{convex hull}
    Let $S\subseteq\mathbb{R}^{n}$. The \textbf{convex hull} of $S$, denoted by
    conv($S$), is the set comprising all the convex combinations of vectors from
    $S$:
    \[
        \text{conv}(S)=\left\{\sum_{i=1}^{k} \lambda_i\mathbf{x}_i:
        \mathbf{x}_i,\mathbf{x}_2,\ldots,\mathbf{x}_k\in S,\pmb{\lambda}\in\Delta_k\right\}
    \]
\end{convex hull}
\underline{\textbf{Comment}}: conv($S$) is the ``smallest'' convex set
containing $S$.

\newmdtheoremenv[style=defEnv]{caratheodory}[theorem]{Theorem}
\begin{caratheodory}
    Let $S\subseteq\mathbb{R}^{n}$ and let $\mathbf{x}\in\text{conv}(S)$. Then
    \[
        \exists\pmb{\lambda}\in\Delta_{n+1},
        \exists\mathbf{x}_1,\mathbf{x}_2,\ldots,\mathbf{x}_{n+1}\in S
        \text{ s.t. }
        \mathbf{x}=\sum_{i=1}^{n+1} \lambda_i\mathbf{x}_i.
    \]
\end{caratheodory}

\newtheorem{caratheodory example}[theorem]{Example}
\begin{caratheodory example}
    For $n=2$, consider the four vectors
    \[
        \mathbf{x}_1=
        \begin{pmatrix}
            1 \\
            1
        \end{pmatrix},
        \mathbf{x}_2=
        \begin{pmatrix}
            1 \\
            2
        \end{pmatrix},
        \mathbf{x}_3=
        \begin{pmatrix}
            2 \\
            1
        \end{pmatrix},
        \mathbf{x}_4=
        \begin{pmatrix}
            2 \\
            2
        \end{pmatrix},
    \]
    and let
    $\mathbf{x}\in\text{conv}(\left\{\mathbf{x}_1,\mathbf{x}_2,\mathbf{x}_3,\mathbf{x}_4\right\})$
    be given by
    \[
        \mathbf{x}=\frac{1}{8}\mathbf{x}_1+\frac{1}{4}\mathbf{x}_2+\frac{1}{2}\mathbf{x}_3+\frac{1}{8}\mathbf{x}_4
        =
        \begin{pmatrix}
            \dfrac{13}{8} \\[2ex]
            \dfrac{11}{8}
        \end{pmatrix}
        \quad\Longrightarrow\quad
        \pmb{\lambda}=
        \begin{pmatrix}
            1/8 \\
            1/4 \\
            1/2 \\
            1/8
        \end{pmatrix},
    \]
    We can find out that
    \[
        (\mathbf{x}_2-\mathbf{x}_1)
        +(\mathbf{x}_3-\mathbf{x}_1)
        -(\mathbf{x}_4-\mathbf{x}_1)=0
        \quad\Longrightarrow\quad
        \pmb{\mu}=
        \begin{pmatrix}
            -1 \\
            1 \\
            1 \\
            -1
        \end{pmatrix}.
    \]
    Since we need to satisfy that $\forall i\in\left\{1,2,3,4\right\}$,
    $\lambda_i+\alpha\mu_i\ge 0$, we need to compute
    \[
        \epsilon=\underset{i:\mu_i<0}{\min}\left\{-\frac{\lambda_i}{\mu_i}\right\}
    \]
    so that $\lambda_j+\epsilon\mu_j=0$ for
    $j\in\underset{i:\mu_i<0}{\text{argmin}}\left\{-\dfrac{\lambda_i}{\mu_i}\right\}$,
    thereby reducing the number of $\mathbf{x}_i$'s required for expressing
    $\mathbf{x}$. From the four inequalities, we can obtain that
    \[
        \begin{cases}
            \alpha\le 1/8 \\
            \alpha\ge -1/4 \\
            \alpha\ge -1/2 \\
            \alpha\le 1/8 \\
        \end{cases} 
    \]
    and $\epsilon=\frac{1}{8}$. Substituting $\alpha=\epsilon$, we can obtain
    that
    \[
        \mathbf{x}=\frac{3}{8}\mathbf{x}_2+\frac{5}{8}\mathbf{x}_3.
    \]
\end{caratheodory example}


\newmdtheoremenv[style=defEnv]{extreme points}[theorem]{Definition}
\begin{extreme points}
    Let $S\subseteq\mathbb{R}^{n}$ be a convex set. A point $\mathbf{x}\in S$ is
    called an \textbf{extreme point} of $S$ if
    $\nexists\mathbf{x}_1,\mathbf{x}_2\in S(\mathbf{x}_1\neq\mathbf{x}_2$
    and $\lambda\in(0,1)$, s.t.
    $\mathbf{x}=\lambda\mathbf{x}_1+(1-\lambda)\mathbf{x}_2$.
    The set of extreme point is denoted by ext($S$).
\end{extreme points}

\newmdtheoremenv[style=defEnv]{krein-milman}[theorem]{Theorem}
\begin{krein-milman}
    Let $S\subseteq\mathbb{R}^{n}$ be a compact convex set.
    Then
    \[
        S=\text{conv}(\text{ext}(S)).
    \]
\end{krein-milman}

\section{Convex Functions}

\newmdtheoremenv[style=defEnv]{convex function}[theorem]{Definition}
\begin{convex function}
    A function $f:C\rightarrow\mathbb{R}$ defined on a convex set
    $C\subseteq\mathbb{R}^{n}$ is called \textbf{convex} (or convex over $C$) if
    \[
        \forall\mathbf{x},\mathbf{y}\in C,\lambda\in[0,1],
        f(\lambda\mathbf{x}+(1-\lambda)\mathbf{y})\le
        \lambda f(\mathbf{x})+(1-\lambda)f(\mathbf{y})
    \]
\end{convex function}

\newmdtheoremenv[style=defEnv]{strict convex function}[theorem]{Definition}
\begin{strict convex function}
    A function $f:C\rightarrow\mathbb{R}$ defined on a convex set
    $C\subseteq\mathbb{R}^{n}$ is called \textbf{strict convex} if
    \[
        \forall\mathbf{x}\neq\mathbf{y}\in C,\lambda\in(0,1),
        f(\lambda\mathbf{x}+(1-\lambda)\mathbf{y})<
        \lambda f(\mathbf{x})+(1-\lambda)f(\mathbf{y})
    \]
\end{strict convex function}

\newmdtheoremenv[style=defEnv]{concavity}[theorem]{Definition}
\begin{concavity}
    A function is called \textbf{concave} if $-f$ is convex. Similarly, $f$ is
    called \textbf{strictly concave} if $-f$ is strictly convex.
\end{concavity}

\newtheorem{convex function example}[theorem]{Example}
\begin{convex function example}
    Several examples of convex functions:
    \begin{itemize}
        \item Affine functions: $f(\mathbf{x})=a^T\mathbf{x}+b$, where
            $a\in\mathbb{R}^n$ and $b\in\mathbb{R}$. Take
            $\mathbf{x},\mathbf{y}\in\mathbb{R}^{n}$ and $\lambda\in[0,1]$, then
            \[
                f(\lambda\mathbf{x}+(1-\lambda)\mathbf{y})=
                \lambda f(\mathbf{x})+(1-\lambda)f(\mathbf{y}).
            \]
        \item Norms: $g(\mathbf{x})=\norm{\mathbf{x}}$. Take
            $\mathbf{x},\mathbf{y}\in\mathbb{R}^{n}$ and $\lambda\in[0,1]$, then
            \[
                g(\lambda\mathbf{x}+(1-\lambda)\mathbf{y})\le
                \norm{\lambda\mathbf{x}}+\norm{(1-\lambda)\mathbf{y}}=
                \lambda g(\mathbf{x})+(1-\lambda)g(\mathbf{y})
            \]
    \end{itemize} 
\end{convex function example}

\newmdtheoremenv[style=defEnv]{jensen's inequality}[theorem]{(Jensen's Inequality) Theorem}
\begin{jensen's inequality}
    Let $f:C\rightarrow\mathbb{R}$ be a convex function where
    $C\subseteq\mathbb{R}^{n}$ is a convex set. Then $\forall
    \mathbf{x}_1,\mathbf{x}_2,\ldots,\mathbf{x}_k\in C$ and
    $\pmb{\lambda}\in\Delta_k$,
    \[
        f\left(\sum_{i=1}^{k} \lambda_i\mathbf{x}_i\right)\le
        \sum_{i=1}^{k} \lambda_i f(\mathbf{x}_i).
    \]
\end{jensen's inequality}


\section{First-order Characterization of Convex Functions}

\newmdtheoremenv[style=defEnv]{gradient inequality}[theorem]{Theorem}
\begin{gradient inequality}
    Let $f:C\rightarrow\mathbb{R}$ be a continuously differentiable function
    defined on a convex set $C\subseteq\mathbb{R}^{n}$. Then 
    \[
        f \text{ is convex over } C
        \quad\iff\quad
        \forall\mathbf{x},\mathbf{y}\in C,
        f(\mathbf{x})+\nabla f(\mathbf{x})^T(\mathbf{y}-\mathbf{x})\le
        f(\mathbf{y})
    \]
    An analogous result holds for strictly convex functions with a strict
    inequality.
\end{gradient inequality}
\underline{\textbf{Comment}}: For a convex function $f$ defined on
$\mathbb{R}^{2}$, the tangent plane at
every point is always below $f$.

\newmdtheoremenv[style=defEnv]{stationarity implies global optimality}[theorem]
{(Global optimality test for convex(concave) function) Theorem}
\begin{stationarity implies global optimality}
    Let $f$ be a continuously differentiable function which is
    \underline{convex} over a
    convex set $C\subseteq\mathbb{R}^{n}$. 
    Then
    \[
        \nabla f(\mathbf{x}^*)=0\text{ for some }\mathbf{x}^*\in C
        \quad\Longrightarrow\quad
        \mathbf{x}^*\text{ is the global \underline{minimizer} of $f$ over $C$.}
    \]
    This is the same for concave function being related to global maximizer.
\end{stationarity implies global optimality}

\newmdtheoremenv[style=defEnv]{convexity of quadratic function}[theorem]
{(Convexity of quadratic function) Theorem}
\begin{convexity of quadratic function}
    Let $f:\mathbb{R}^{n}\rightarrow\mathbb{R}$ be the quadratic function given
    by $f(\mathbf{x})=\mathbf{x}^TA\mathbf{x}+2\mathbf{b}^T\mathbf{x}+c$ where
    $A\in\mathbb{R}^{n\times n}$ is symmetric, $b\in\mathbb{R}^{n}$, and
    $c\in\mathbb{R}$. Then
    \[
        f\text{ is (strictly) convex}
        \quad\iff\quad
        A\succeq 0(A\succ 0).
    \]
\end{convexity of quadratic function}

\newmdtheoremenv[style=defEnv]{monotonicity of the gradient}[theorem]
{(Monotonicity of the gradient) Theorem}
\begin{monotonicity of the gradient}
    Suppose that $f$ is a continuously differentiable function over a convex set
    $C\subseteq\mathbb{R}^{n}$, then
    \[
        f\text{ is convex over }C
        \quad\iff\quad
        \forall\mathbf{x},\mathbf{y}\in C,
        {(\nabla f(\mathbf{x})-\nabla
        f(\mathbf{y}))}^T(\mathbf{x}-\mathbf{y})\ge 0.
    \]
    An analogous result holds for strictly convex functions with a strict
    inequality.
\end{monotonicity of the gradient}

\begin{proof}
    If $f$ is convex, then
    \[
        f(y)\ge f(x)+\nabla f(x)\cdot(y-x)
    \]
    and
    \[
        f(x)\ge f(y)+\nabla f(y)\cdot(x-y)
    \]
    so that by adding the above inequalities, we obtain the result.
\end{proof} 

\section{Second-order Characterization of Convex Functions}

\newmdtheoremenv[style=defEnv]{second-order characterization of convexity}[theorem]{Theorem}
\begin{second-order characterization of convexity}
    Let $f$ be a twice continuously differentiable function over an open convex
    set $C\subseteq\mathbb{R}^{n}$. Then
    \[
        f\text{ is convex over }C
        \quad\iff\quad
        \forall\mathbf{x}\in C,
        \nabla^2f(\mathbf{x})\succeq 0
    \]
\end{second-order characterization of convexity}

\newtheorem{second-order characterization of convexity eg}[theorem]{Example}
\begin{second-order characterization of convexity eg}
    Convexity of the log-sum-exp function
    \[
        f(\mathbf{x})=\log{(e^{x_1}+e^{x_2}+\cdots+e^{x_n})},\;\mathbf{x}\in\mathbb{R}^{n}.
    \]
    The gradient is given by
    \[
        \frac{\partial f}{\partial
        x_i}(\mathbf{x})=\frac{e^{x_i}}{\sum_{j=1}^{n} e^{x_j}},
        \quad i=1,2,\ldots,n.
    \]
    Therefore, the Hessian is computed as
    \[
        \frac{\partial^2f}{\partial x_i\partial x_j}(\mathbf{x})=
        \begin{cases}
            -\frac{e^{x_i}e^{x_j}}{{\left(\sum_{j=1}^{n} e^{x_j}\right)}^{2}}
            & i \neq j \\
            -\frac{e^{x_i}e^{x_j}}{{\left(\sum_{j=1}^{n} e^{x_j}\right)}^{2}}
            +\frac{e^{x_i}}{\sum_{j=1}^{n} e^{x_j}}
            & i = j
        \end{cases} 
    \]
    We can thus write the Hessian matrix as
    \[
        \nabla^2f(\mathbf{x})=\text{diag}(\mathbf{w})-\mathbf{w}\mathbf{w}^T,
        \quad\text{with}\quad
        \mathbf{w}={\left(\frac{e^{x_i}}{\sum_{j=1}^{n}
        e^{x_j}}\right)}^{n}_{i=1}
        \in\Delta_n.
    \]
    For any $\mathbf{v}\in\mathbb{R}^{n}$,
    \[
        \mathbf{v}^T\nabla^2f(\mathbf{x})\mathbf{v}=
        \sum_{i=1}^{n} w_iv_i^2-{(\mathbf{v}^T\mathbf{w})}^{2}\ge 0,
    \]
    since defining $s_i=\sqrt{w_i}v_i,t_i=\sqrt{w_i}$, we have
    \[
        (\mathbf{v}^T\mathbf{w})^2={(\mathbf{s}^T\mathbf{t})}^{2}
        \le\norm{\mathbf{s}}^2\norm{\mathbf{t}}^2
        =\left(\sum_{i=1}^{n} w_iv_i^2\right)\left(\sum_{i=1}^{n} w_i\right)
        =\sum_{i=1}^{n} w_iv_i^2.
    \]
    Thus $\nabla^2f(\mathbf{x})\succeq 0$ and hence $f$ is convex over
    $\mathbb{R}^{n}$.
\end{second-order characterization of convexity eg}

\section{More Results of Convex Function}

\newmdtheoremenv[style=defEnv]{operations preserving convexity}[theorem]{Theorem}
\begin{operations preserving convexity}
    Let $f,f_1,f_2,\ldots,f_p$ be convex functions over a convex set
    $C\subseteq\mathbb{R}^{n}$.
    \begin{itemize}
        \item Let $\alpha\ge 0$, then $\alpha f$ is a convex function over $C$.
        \item The sum function $\sum_{i=1}^{p} f_i$ is convex over $C$.
        \item Let $A\in\mathbb{R}^{n\times m}$ and
            $\mathbf{b}\in\mathbb{R}^{n}$. Then the function
            $g(\mathbf{y})=f(A\mathbf{y}+\mathbf{b})$
            is convex over the convex set
            $D=\left\{\mathbf{y}\in\mathbb{R}^{m}:A\mathbf{y}+\mathbf{b}\in C\right\}$.
        \item Let $g:I\rightarrow\mathbb{R}$ be a nondecreasing
            convex function over the interval $I\subseteq\mathbb{R}$.
            Assume that the image of $C$ under $f$ is contained in $I$:
            $f(C)\subseteq I$, then the composition of $g$ and $f$ defined by
            $h(\mathbf{x})\equiv g(f(\mathbf{x}))$ is convex over $C$.
    \end{itemize} 
\end{operations preserving convexity}

\newmdtheoremenv[style=defEnv]{point-wise maximum of convex functions}[theorem]
{(Point-wise maximum of convex functions) Theorem}
\begin{point-wise maximum of convex functions}
    Let $f_1,f_2,\ldots,f_p:C\rightarrow\mathbb{R}$ be $p$ convex functions over
    the convex set $C\subseteq\mathbb{R}^{n}$, then the maximum function
    \[
        f(\mathbf{x})\equiv
        \underset{i=1,2,\ldots,p}{\max}\left\{f_i(\mathbf{x})\right\}
    \]
    is convex over $C$.
\end{point-wise maximum of convex functions}

\newmdtheoremenv[style=defEnv]{preservation of convexity under partial min}[theorem]{Theorem}
\begin{preservation of convexity under partial min}
    Let $f:C\times D\rightarrow\mathbb{R}$ be a convex function defined over the
    set $C\times D$ where $C\subseteq\mathbb{R}^{m}$ and
    $D\subseteq\mathbb{R}^{n}$ are convex sets. Let
    \[
        g(\mathbf{x})=\underset{\mathbf{y}\in D}{\min}f(\mathbf{x},\mathbf{y}),
        \quad\mathbf{x}\in C
    \]
    where we assume that the minimum is finite. Then $g$ is convex over $C$.
\end{preservation of convexity under partial min}
\newtheorem{partial min example}[theorem]{Example}
\begin{partial min example}
    The distance function from a convex set $d_C(\mathbf{x})\equiv
    \underset{y\in C}{\inf}\norm{\mathbf{x}-\mathbf{y}}$.
\end{partial min example}

\newmdtheoremenv[style=defEnv]{continuity of convex functions}[theorem]{Theorem}
\begin{continuity of convex functions}
    Let $f:C\rightarrow\mathbb{R}$ be a convex function defiend over a convex
    set $C\subseteq\mathbb{R}^{n}$. Let $\mathbf{x}_0\in\text{int}(C)$. Then
    $\exists\epsilon>0,L>0$ s.t. $B[\mathbf{x}_0,\epsilon]\subseteq C$ and
    \[
        \forall \mathbf{x}\in B[\mathbf{x}_0,\epsilon],
        |f(\mathbf{x})-f(\mathbf{x}_0)|\le L\norm{\mathbf{x}-\mathbf{x}_0}.
    \]
\end{continuity of convex functions}

\newmdtheoremenv[style=defEnv]{existence of directional derivative of convex function}[theorem]{Theorem}
\begin{existence of directional derivative of convex function}
    Let $f:C\rightarrow\mathbb{R}$ be a convex function over the convex set
    $C\subseteq\mathbb{R}^{n}$. Let $\mathbf{x}\in\text{int}(C)$. Then
    \[
        \forall \mathbf{d}\neq\mathbf{0}, \exists f'(\mathbf{x};\mathbf{d}).
    \]
\end{existence of directional derivative of convex function}

\newmdtheoremenv[style=defEnv]{no maximum inside the convex set}[theorem]{Theorem}
\begin{no maximum inside the convex set}
    Let $f:C\rightarrow\mathbb{R}$ be convex and non-constant over the nonempty
    convex set $C\subseteq\mathbb{R}^{n}$. Then $f$ does not attain a maximum at
    a point in int($C$).
\end{no maximum inside the convex set}

\newmdtheoremenv[style=defEnv]{maximum of a convex function over a compact convex set}[theorem]{Theorem}
\begin{maximum of a convex function over a compact convex set}
    Let $f:C\rightarrow\mathbb{R}$ be convex over the nonempty convex and
    compact set $C\subseteq\mathbb{R}^{n}$. Then there exists at least one
    maximizer of $f$ over $C$ that is an extreme point of $C$.
\end{maximum of a convex function over a compact convex set}


\chapter{Convex Optimization}

\section{Problem Definition}

A \textbf{convex optimization problem} is a problem consisting of minimizing a
convex function $f(\mathbf{x})$ over a convex set $C$:
\begin{equation}\label{eq:CVX}
    \tag{CVX}
    \begin{array}{c @{\quad} l}
        \min & f(\mathbf{x}) \\
        \text{ s.t.} & \mathbf{x}\in C
    \end{array} 
\end{equation} 
A functional form of a convex problem can be written as
\begin{equation*}
    \begin{array}{c @{\quad} l @{\quad} l}
        \min & f(\mathbf{x}) & \\
        \text{s.t.} & g_i(\mathbf{x})\le 0, & i=1,2,\ldots,m \\
        & h_j(\mathbf{x})=0, & j=1,2,\ldots,p,
    \end{array} 
\end{equation*} 
where $f,g_1,g_2,\ldots,g_m:\mathbb{R}^{n}\rightarrow\mathbb{R}$ are convex
functions, and $h_1,h_2,\ldots,h_p:\mathbb{R}^{m}\rightarrow\mathbb{R}$
are affine functions.
The functional form does fit into the general formulation~\eqref{eq:CVX}.

\newmdtheoremenv[style=defEnv]{local minima are global in CVX}[theorem]{Theorem}
\begin{local minima are global in CVX}
    Let $f:C\rightarrow\mathbb{R}$ be a (strict) convex function 
    defined on the convex set $C\subseteq\mathbb{R}^{n}$.
    Let $\mathbf{x}^*\in C$ be a local minimum of $f$ over $C$.
    Then $\mathbf{x}^*$ is a strict global minimum of $f$ over $C$.
\end{local minima are global in CVX}

\newmdtheoremenv[style=defEnv]{CVX optimal solutions are convex}[theorem]{Theorem}
\begin{CVX optimal solutions are convex}
    Let $f:C\rightarrow\mathbb{R}$ be a (strict) convex function 
    defined on the convex set $C\subseteq\mathbb{R}^{n}$.
    Then the set of optimal solutions of the problem
    \[
        \min{\left\{f(\mathbf{x}):\mathbf{x}\in C\right\}}
    \]
    is convex. If, in addition, $f$ is strictly convex over $C$, then there
    exists at most one optimal solution of the problem.
\end{CVX optimal solutions are convex}

\newtheorem{CVX example}[theorem]{Example}
\begin{CVX example}
    \;

    \begin{itemize}
        \item A convex problem:
            \begin{equation*}
                \begin{array}{c @{\quad} l}
                    \min & -2x_1+x_2 \\
                    \text{s.t.} & x_1^2+x_2^2\le 3
                \end{array} 
            \end{equation*} 
        \item A nonconvex problem:
            \begin{equation*}
                \begin{array}{c @{\quad} l}
                    \min & x_1^2-x_2 \\
                    \text{s.t.} & x_1^2+x_2^2=3
                \end{array} 
            \end{equation*} 
        \item \textbf{Linear Programming}:
            \begin{equation*}
                \begin{array}{c @{\quad} c @{\quad} l}
                    & \min & \mathbf{c}^T\mathbf{x} \\
                    (\text{\textbf{LP}}): & \text{s.t.} & A\mathbf{x}\le\mathbf{b} \\
                                          & & B\mathbf{x}=\mathbf{g}
                \end{array} 
            \end{equation*} 
            
        \item Convex quadratic problems: minimizing a convex function quadratic
            function subject to affine constraints. The general form is
            \begin{equation*}
                \begin{array}{c @{\quad} l}
                    \min & \mathbf{x}^TQ\mathbf{x}+2\mathbf{b}^T\mathbf{x} \\
                    \text{s.t.} & A\mathbf{x}\le \mathbf{c}
                \end{array} 
            \end{equation*} 
            where $Q\in\mathbb{R}^{n\times n}$ is positive semidefinite,
            $\mathbf{b}\in\mathbb{R}^{n}$, $A\in\mathbb{R}^{m\times n}$,
            $\mathbf{c}\in\mathbb{R}^{m}$.
    \end{itemize} 
\end{CVX example}

\section{Stationarity}

Consider the constrained optimization problem given by
\begin{equation}\label{eq:p}
    \tag{P}
    \underset{\mathbf{x}}{\min}\quad\left\{f(\mathbf{x}):\mathbf{x}\in C\right\},
\end{equation}
where $C\subseteq\mathbb{R}^{n}$ is closed and convex,
and $f$ is continuously differentiable over C, not necessarily convex.

\newmdtheoremenv[style=defEnv]{stationarity}[theorem]{Definition}
\begin{stationarity}
    $\mathbf{x}^*$ is called a \textbf{stationary point}
    of~\eqref{eq:p} if
    \[
        \forall \mathbf{x}\in C,\;
        \nabla f(\mathbf{x}^*)^T(\mathbf{x}-\mathbf{x}^*)\ge 0.
    \]
    
\end{stationarity}

\newmdtheoremenv[style=defEnv]{stationarity as a necessary optimality condition}[theorem]{Theorem}
\begin{stationarity as a necessary optimality condition}
    Let $f$ be a continuously differentiable function over a nonempty closed
    convex set $C$, and let $\mathbf{x}^*$ be a local minimum of~\eqref{eq:p},
    then $\mathbf{x}^*$ is a stationary point of~\eqref{eq:p}.
\end{stationarity as a necessary optimality condition}

\def\arraystretch{1.5}
\begin{table}[h]
    \centering
    \begin{tabular}{c|c}
        Feasible Set & Explicit Stationarity Condition \\
        \hline\hline
        $\mathbb{R}^{n}$ & $\nabla f(\mathbf{x}^*)=\mathbf{0}$ \\[4px]
        \hline
        $\mathbb{R}_+^n$ & $\frac{\partial f}{\partial x_i}(\mathbf{x}^*)
        \begin{cases}
            =0 & x_i^*>0 \\
            \ge 0 & x_i^*=0
        \end{cases}
        $ \\
        \hline
        $\left\{\mathbf{x}\in\mathbb{R}^{n}:\mathbf{e}^T\mathbf{x}=1\right\}$
                         & $\frac{\partial f}{\partial
                         x_1}(\mathbf{x}^*)=\cdots=\frac{\partial f}{\partial
                         x_n}(\mathbf{x}^*)$ \\
        \hline
        $B[\mathbf{0},\mathbf{1}]$ 
                         & $\nabla f(\mathbf{x}^*)=\mathbf{0}$ or
                         $\norm{\mathbf{x}^*}=1$ and $\exists \lambda\le
                         0:\nabla f(\mathbf{x}^*)=\lambda\mathbf{x}^*$
    \end{tabular} 
\end{table} 
\def\arraystretch{1.0}

\newmdtheoremenv[style=defEnv]{stationarity in convex optimization}[theorem]{Theorem}
\begin{stationarity in convex optimization}
    Let $f$ be a continuously differentiable function over a nonempty closed
    convfex set $C\subseteq\mathbb{R}^{n}$, then $\mathbf{x}^*$ is a stationary
    point of~\eqref{eq:p} iff $\mathbf{x}^*$ is an optimal solution
    of~\eqref{eq:p}.
\end{stationarity in convex optimization}

\section{Orthogonal Projection Operator}

\newmdtheoremenv[style=defEnv]{orthogonal projection}[theorem]{Definition}
\begin{orthogonal projection}
    Given a nonempty closed convex set $C$, the orthogonal projection operator
    $P_C:\mathbb{R}^{n}\rightarrow C$ is defined by
    \[
        P_C(\mathbf{x})=\text{argmin}\left\{\norm{\mathbf{y}-\mathbf{x}}^2:\mathbf{y}\in
        C\right\}.
    \]
\end{orthogonal projection}

\newmdtheoremenv[style=defEnv]{1 projection theorem}[theorem]{Theorem}
\begin{1 projection theorem}
    Let $C\subseteq\mathbb{R}^{n}$ be a nonempty closed convex set, then
    \[
        \forall \mathbf{x}\in\mathbb{R}^{n},
        \exists ! P_C(\mathbf{x})
    \]
    
\end{1 projection theorem}

\newmdtheoremenv[style=defEnv]{2 projection theorem}[theorem]{Theorem}
\begin{2 projection theorem}
    Let $C$ be a nonempty closed convex set and let
    $\mathbf{x}\in\mathbb{R}^{n}$, then
    \[
        \mathbf{z}=P_C(\mathbf{x})
        \quad\iff\quad
        \forall \mathbf{y}\in C,
        (\mathbf{x}-\mathbf{z})^T(\mathbf{y}-\mathbf{z})\le 0.
    \]
    
\end{2 projection theorem}

\newtheorem{examples of orthogonal projections}[theorem]{Example}
\begin{examples of orthogonal projections}
    \;

    \begin{itemize}
        \item For $C=\mathbb{R}_+^n$,
            \[
                P_{\mathbb{R}_+^n}(\mathbf{x})={[\mathbf{x}]}_{+}
            \]
            where
            ${[\mathbf{x}]}_{+}={(\max{\left\{x_1,0\right\}},\max{\left\{x_2,0\right\}},\ldots,\max{\left\{x_n,0\right\}})}^{T}$.
            
        \item A \textbf{box} is a subset of $\mathbb{R}^{n}$ of the form
            \[
                B=[l_1,u_1]\times[l_2,u_2]\times\cdots\times[l_n,u_n]
                =\left\{\mathbf{x}\in\mathbb{R}^{n}:l_i\le x_i\le u_i\right\},
            \]
            where $l_i\le u_i\;\forall i=1,2,\ldots,n$ . For this set
            \[
                {[P_B(\mathbf{x})]}_{i}=
                \begin{cases}
                    u_i & x_i\ge u_i \\
                    x_i & l_i<x_i<u_i \\
                    l_i & x_i\le l_i.
                \end{cases}
            \]
        \item For the closed ball in $\mathbb{R}^{n}$, $C=B[\mathbf{0},r]$, it
            holds
            \[
                P_{B[\mathbf{0},r]}(\mathbf{x})=
                \begin{cases}
                    \mathbf{x} & \norm{\mathbf{x}}\le r \\
                    r \frac{\mathbf{x}}{\norm{\mathbf{x}}} &
                    \norm{\mathbf{x}}>r.
                \end{cases}
            \]
    \end{itemize}
\end{examples of orthogonal projections}

\newmdtheoremenv[style=defEnv]{representation of stationarity via P_C}[theorem]{Theorem}
\begin{representation of stationarity via P_C}
    Let $f$ be a continuously differentiable function over the nonempty closed
    convex set $C$, and let $s>0$. Then 
    \[
        \mathbf{x}^*\text{ is a stationary point of~\eqref{eq:p}}
        \quad\iff\quad
        \mathbf{x}^*=P_C(\mathbf{x}^*-s\nabla f(\mathbf{x}^*)).
    \]
\end{representation of stationarity via P_C}

\section{Gradient Projection Method}

\newmdtheoremenv[style=defEnv]{gradient mapping}[theorem]{Definition}
\begin{gradient mapping}
    We can define the \textbf{gradient mapping} as
    \[
        G_L(\mathbf{x})=L\left[\mathbf{x}-P_C\left(\mathbf{x}-\frac{1}{L}\nabla
        f(\mathbf{x})\right)\right]
    \]
    where $L>0$. 
\end{gradient mapping}
\underline{\textbf{Comments}}: 
\begin{itemize}
    \item In the unconstrained case,
        $G_L(\mathbf{x})=\nabla f(\mathbf{x})$ since projecting onto the same point.
        Otherwise, $G_L(\mathbf{x})=\mathbf{0}\iff\mathbf{x}$ is a stationary point.
        We can thus consider $\norm{G_L(\mathbf{x})}^2$ to be 
        \emph{optimality measure}.
    \item Slight modification can be made for gradient descent method to become
        \textbf{gradient projection method} for solving convex optimization
        problem, whose descent step becomes
        \[
            \mathbf{x}^{k+1}=P_C\left(\mathbf{x}^k-t^k\nabla
            f(\mathbf{x}^k)\right)
        \]
        to ensure that at each iteration $i$, $x^{i}$ is within the convex set.
\end{itemize}

\newmdtheoremenv[style=defEnv]{convergence of gradient projection method}[theorem]{Theorem}
\begin{convergence of gradient projection method}
    Let $\left\{\mathbf{x}^k\right\}$ be the sequence generated by the gradient
    projection method for solving problem~\eqref{eq:p} with either a constant
    stepsize $\overline{t}\in\left(0,\frac{2}{L}\right)$, where $L$ is a
    Lipschitz constant of $\nabla f$, or a backtracking stepsize strategy.
    Assume that $f$ is bounded below, then:
    \begin{enumerate}
        \item The sequence $\left\{\mathbf{x}^k\right\}$ is nonincreasing.
        \item $G_d(\mathbf{x}^k)\rightarrow 0$ as $k\rightarrow \infty$, where
            \[
                d=
                \begin{cases}
                    1 / \overline{t} & \text{constant stepsize} \\
                    1 / s & \text{backtracking}.
                \end{cases}
            \]
    \end{enumerate}
    
\end{convergence of gradient projection method}

\section{Separation Theorem}

\newmdtheoremenv[style=defEnv]{separation theorem}[theorem]{Definition}
\begin{separation theorem}
    A hyperplane
    \[
        H=\left\{\mathbf{x}\in\mathbb{R}^{n}:\mathbf{a}^T\mathbf{x}=b\right\}
        \quad
        (\mathbf{a}\in\mathbb{R}^{n}\backslash\left\{\mathbf{0}\right\},b\in\mathbb{R})
    \]
    is said to \textbf{strictly separate} a point $\mathbf{y}\notin S$ from $S$
    if
    \[
        \mathbf{a}^T\mathbf{y}>b
        \quad\text{and}\quad
        \forall\mathbf{x}\in S,\mathbf{a}^T\mathbf{x}\le b.
    \]
\end{separation theorem}

\newmdtheoremenv[style=defEnv]{separation of a point from closed convex set}[theorem]{Theorem}
\begin{separation of a point from closed convex set}
    Let $C\subseteq\mathbb{R}^{n}$ be a nonempty closed convex set, and let
    $\mathbf{y}\notin C$. Then $\exists
    \mathbf{p}\in\mathbb{R}^n\backslash\left\{\mathbf{0}\right\}$ and
    $\alpha\in\mathbb{R}$ s.t. $\mathbf{p}^T\mathbf{y}>\alpha$ and
    $\mathbf{p}^T\mathbf{x}\le\alpha$ for all $\mathbf{x}\in C$.
\end{separation of a point from closed convex set}

\newmdtheoremenv[style=defEnv]{farkas form 1}[theorem]{(Farkas') Lemma}
\begin{farkas form 1}
    Let $\mathbf{c}\in\mathbb{R}^{n}$ and $A\in\mathbb{R}^{m\times n}$.
    Then exactly one of the following systems has a solution:
    \begin{enumerate}[label = (\roman*)]
        \item $A\mathbf{x}\le \mathbf{0}, \mathbf{c}^T\mathbf{x}>0$.
        \item $A^T\mathbf{y}=\mathbf{c},\mathbf{y}\ge 0$.
    \end{enumerate}
\end{farkas form 1}

\newmdtheoremenv[style=defEnv]{farkas form 2}[theorem]{Lemma}
\begin{farkas form 2}
    Let $\mathbf{c}\in\mathbb{R}^{n}$ and $A\in\mathbb{R}^{m\times n}$.
    Then the following two claims are equivalent:
    \begin{enumerate}[label = (\alph*)]
        \item The implication 
            $A\mathbf{x}\le\mathbf{0}\;\Rightarrow\;\mathbf{c}^T\mathbf{x}\le 0$
            holds true.
        \item $\exists \mathbf{y}\in\mathbb{R}_+^{m}$ s.t.
            $A^T\mathbf{y}=\mathbf{c}$.
    \end{enumerate}
\end{farkas form 2}

\newmdtheoremenv[style=defEnv]{gordan's alternative theorem}[theorem]{Theorem}
\begin{gordan's alternative theorem}
    Let $A\in\mathbb{R}^{m\times n}$, then exactly one of the following two
    systems has a solution:
    \begin{enumerate}[label = (\roman*)]
        \item $A\mathbf{x}<\mathbf{0}$
        \item $\mathbf{p}\neq \mathbf{0},A^T\mathbf{p}=0,\mathbf{p}\ge \mathbf{0}$.
    \end{enumerate}
\end{gordan's alternative theorem}


\section{KKT Conditions}

\newmdtheoremenv[style=defEnv]{KKT for linearly constrained problems}[theorem]{Theorem}
\begin{KKT for linearly constrained problems}
    Consider the minimization problem
    \begin{equation}\label{eq:lcp}
        \tag{LCP}
        \begin{array}{c @{\quad} l @{\quad} l}
            \min & f(\mathbf{x}) & \\
            \text{subject to} & \mathbf{a}_i^T\mathbf{x}\le b_i & i=1,2,\ldots,m \\
        \end{array} 
    \end{equation} 
    where $f$ is continuously differentiable over $\mathbb{R}^{n}$,
    $\mathbf{a}_i\in\mathbb{R}^{n}$, $b_i\in\mathbb{R}$, and let $\mathbf{x}^*$
    be a local minimum point of~\eqref{eq:lcp}. Then $\exists \lambda_i\ge 0$
    s.t.
    \[
        \nabla f(\mathbf{x}^*)+\sum_{i=1}^{m} \lambda_i\mathbf{a}_i=\mathbf{0}
        \quad\text{and}\quad
        \lambda_i(\mathbf{a}_i^T\mathbf{x}^*-b_i)=0
    \]
    where the above equations are called the \textbf{KKT condition} or
    \textbf{KKT system}.
\end{KKT for linearly constrained problems}

\newmdtheoremenv[style=defEnv]{KKT for convex linearly constrained problem}[theorem]{Theorem}
\begin{KKT for convex linearly constrained problem}
    Consider the problem~\eqref{eq:lcp} where additionally $f$ is convex.
    Then $\mathbf{x}^*$ is an optimal solution $\iff$ $\exists \lambda_i\ge 0$ s.t.
    \[
        \nabla f(\mathbf{x}^*)+\sum_{i=1}^{m} \lambda_i\mathbf{a}_i=\mathbf{0}
        \quad\text{and}\quad
        \lambda_i(\mathbf{a}_i^T\mathbf{x}^*-b_i)=0
    \]
\end{KKT for convex linearly constrained problem}

\newmdtheoremenv[style=defEnv]{KKT for LCP}[theorem]{Theorem}
\begin{KKT for LCP}
    Consider the minimization problem
    \begin{equation}\label{eq:lcpi}
        \tag{LCPI}
        \begin{array}{c @{\quad} l @{\quad} l}
            \min & f(\mathbf{x}) & \\
            \text{subject to} & \mathbf{a}_i^T\mathbf{x}\le b_i & i=1,2,\ldots,m \\
                              & \mathbf{c}_j^T\mathbf{x}=d_j, & j=1,2,\ldots,p
        \end{array} 
    \end{equation} 
    where $f$ is continuously differentiable,
    $\mathbf{a}_i,\mathbf{c}_j\in\mathbb{R}^{n}$, $b_i,d_j\in\mathbb{R}$.
    \begin{enumerate}[label = (\roman*)]
        \item (Necessity of the KKT condition)
            If $\mathbf{x}^*$ is a local minimum of~\eqref{eq:lcpi}, then
            $\mathbf{x}^*$ satisfies the KKT condition, i.e.\
            $\exists\lambda_i\ge 0$ and $\mu_i\in\mathbb{R}$ s.t.
            \begin{equation*}
                \begin{array}{r @{\quad} l}
                    \nabla f(\mathbf{x}^*)+\sum_{i=1}^{m}
                    \lambda_i\mathbf{a}_i+\sum_{j=1}^{p} \mu_j\mathbf{c}_j=0, &
                    \\[1ex]
                    \lambda_i(\mathbf{a}_i^T\mathbf{x}^*-b_i)=0, &
                    i=1,2,\ldots,m.
                \end{array} 
            \end{equation*}
        \item (Sufficiency in the convex case) If $f$ is convex over
            $\mathbb{R}^{n}$ and $\mathbf{x}^*$ is a feasible solution
            of~\eqref{eq:lcpi} for which $\exists\lambda_i\ge 0$ and
            $\mu_i\in\mathbb{R}$ s.t. the KKT conditions are satisfied, then
            $\mathbf{x}^*$ is an optimal solution of~\eqref{eq:lcpi}.
    \end{enumerate}
\end{KKT for LCP}

\newtheorem{KKT LCPI example}[theorem]{Example}
\begin{KKT LCPI example}
    Solve the problem
    \begin{equation*}
        \begin{array}{c @{\quad} l}
            \min & \frac{1}{2}(x_1^2+x_2^2+x_3^2) \\
            \text{s.t.} & x_1+x_2+x_3=3.
        \end{array} 
    \end{equation*} 
    Since the function is convex, and the constraint is a hyperplane which is a
    convex set, KKT conditions are \underline{necessary and sufficient} for this problem.

    \medskip\noindent
    Now we assemble the \textbf{Lagrangian}
    \[
        L(\mathbf{x},\mu)=\frac{1}{2}(x_1^2+x_2^2+x_3^2)+\mu(x_1+x_2+x_3-3)
    \]
    and solve for the KKT system, which is to find $\mathbf{x}^*, \mu^*$ s.t.
    \[
        \nabla_\mathbf{x}L(\mathbf{x}^*,\mu^*)=0
        \quad\text{subject to}\quad
        x_1+x_2+x_3=3.
    \]
    This translates to
    \[
        \begin{cases}
            \frac{\partial L}{\partial x_1}=x_1+\mu=0 \\
            \frac{\partial L}{\partial x_2}=x_2+\mu=0 \\
            \frac{\partial L}{\partial x_3}=x_3+\mu=0 \\
            x_1+x_2+x_3=3
        \end{cases}
        \Longrightarrow
        \begin{cases}
            \mu=-1 \\
            x_1=x_2=x_3=1.
        \end{cases}
    \]
    Thus, $\mathbf{1}$ is the solution to the problem.
\end{KKT LCPI example}

\section{Orthogonal projections}

\newmdtheoremenv[style=defEnv]{orthogonal projectinos onto affine space}[theorem]{Theorem}
\begin{orthogonal projectinos onto affine space}
    Let $C$ be the affine space
    $C=\left\{\mathbf{x}\in\mathbb{R}^{n}:A\mathbf{x}=\mathbf{b}\right\}$
    where $A\in\mathbb{R}^{m\times n}$ and $\mathbf{b}\in\mathbb{R}^{n}$, then
    \[
        P_C(\mathbf{y})=\mathbf{y}-A^T{(AA^T)}^{-1}(A\mathbf{y}-\mathbf{b}).
    \]
\end{orthogonal projectinos onto affine space}
\newtheorem{hyperplane orthogonal projection}[theorem]{Example}
\begin{hyperplane orthogonal projection}
    Consider the hyperplane
    \[
        H=\left\{\mathbf{x}\in\mathbb{R}^{n}:\mathbf{a}^T\mathbf{x}=b\right\}
        \quad
        \left(\mathbf{0}\neq\mathbf{a}\in\mathbb{R}^{n},b\in\mathbb{R}\right),
    \]
    then by the projection on an affine space result (as shown previously),
    \[
        P_H(\mathbf{y})=\mathbf{y}-\mathbf{a}{(\mathbf{a}^T\mathbf{a})}^{-1}(\mathbf{a}^T\mathbf{y}-b)
        =\mathbf{y}-\frac{\mathbf{a}^T\mathbf{y}-b}{\norm{\mathbf{a}}^2}\mathbf{a}.
    \]
    Thus the distance of $\mathbf{y}$ to the hyperplane $H$ is
    \[
        d(\mathbf{y},H)=\frac{|\mathbf{a}^T\mathbf{y}-b|}{\norm{\mathbf{a}}}.
    \]
\end{hyperplane orthogonal projection}

\newmdtheoremenv[style=defEnv]{distance of a point from a half space}[theorem]{Lemma}
\begin{distance of a point from a half space}
    Let $H^-=\left\{\mathbf{x}\in\mathbb{R}^n:\mathbf{a}^T\mathbf{x}\le
    b\right\}$ where $\mathbf{0}\neq\mathbf{a}\in\mathbb{R}^{n}$ and
    $b\in\mathbb{R}$. Then
    \[
        P_{H^-}(\mathbf{x})=\mathbf{x}-\frac{{[\mathbf{a}^T\mathbf{x}-b]}_{+}}{\norm{\mathbf{a}}^2}\mathbf{a}.
    \]
\end{distance of a point from a half space}

\newmdtheoremenv[style=defEnv]{sufficiency of KKT conditions for convex problem}[theorem]{Theorem}
\begin{sufficiency of KKT conditions for convex problem}
    Let $\mathbf{x}^*$ be a feasible solution of
    \begin{equation}\label{eq:nlp}
        \tag{NLP}
        \begin{array}{c @{\quad} l @{\quad} l}
            \min & f(\mathbf{x}) & \\
            \text{subject to} & g_i(\mathbf{x})\le 0, & i=1,2,\ldots,m \\
                              & h_j(\mathbf{x})=0, & j=1,2,\ldots,p
        \end{array} 
    \end{equation} 
    where $f,g_i$ are continuously differentiable functions over
    $\mathbb{R}^{n}$ and $h_i$ are affine functions. We can define the
    \textbf{Lagrangian}
    \[
        L(\mathbf{x},\pmb{\lambda},\pmb{\mu})=
        f(\mathbf{x})+\sum_{i=1}^{m} \lambda_ig_i(\mathbf{x})
        +\sum_{j=1}^{p} \mu_jh_j(\mathbf{x})
    \]
    s.t.
    \[
        \nabla_\mathbf{x}L(\mathbf{x^*},\pmb{\lambda},\pmb{\mu}) = 0
        \quad\text{and}\quad
        \lambda_ig_i(\mathbf{x}^*)=0,
    \]
    then $\mathbf{x}^*$ is an optimal solution of~\eqref{eq:nlp}.
\end{sufficiency of KKT conditions for convex problem}

\newmdtheoremenv[style=defEnv]{necessity of the KKT conditions under slater}[theorem]{Theorem}
\begin{necessity of the KKT conditions under slater}
    Let $\mathbf{x}^*$ be an optimal solution of the problem
    \begin{equation}\label{eq:nlp2}
        \tag{NLP2}
        \begin{array}{c @{\quad} l @{\quad} l}
            \min & f(\mathbf{x}) & \\
            \text{subject to} & g_i(\mathbf{x})\le 0, & i=1,2,\ldots,m \\
                              & h_j(\mathbf{x})\le 0, & j=1,2,\ldots,p \\
                              & s_k(\mathbf{x})=0, & k=1,2,\ldots,q
        \end{array} 
    \end{equation} 
    where $f,g_i$ are continuously differentiable convex functions over
    $\mathbb{R}^{n}$, $h_i,s_i$ are affine functions.
    Suppose $\exists \hat{\mathbf{x}}$ satisfying the generalized \textbf{Slater's
    condition}:
    \begin{align*}
        g_i(\hat{\mathbf{x}})<0, &\quad i = 1,2,\ldots,m \\
        h_j(\hat{\mathbf{x}})\le 0, &\quad j = 1,2,\ldots,p \\
        s_k(\hat{\mathbf{x}})=0, &\quad k = 1,2,\ldots,q
    \end{align*}
    then $\exists \lambda_i,\eta_j\ge 0$ and $\mu_i\in\mathbb{R}$ s.t.
    \begin{equation*}
        \begin{array}{r @{\quad} l}
            \nabla f(\mathbf{x}^*)+\sum_{i=1}^{m}
            \lambda_i\nabla g_i(\mathbf{x}^*)+\sum_{j=1}^{p} \eta_j\nabla
            h_j(\mathbf{x}^*)+\sum_{k=1}^{q} \mu_k\nabla s_k(\mathbf{x}^*)=0, &
            \\[1ex]
            \lambda_i g_i(\mathbf{x}^*)=0, &
            i=1,2,\ldots,m \\[1ex]
            \eta_j h_j(\mathbf{x}^*)=0, &
            j=1,2,\ldots,p.
        \end{array} 
    \end{equation*}
\end{necessity of the KKT conditions under slater}


\chapter{Duality}

\section{The Primal and Dual Problems}

Consider the problem
\begin{equation}\label{eq:primal}
    \tag{Primal}
    \begin{array}{c @{\quad} l @{\quad} l}
        \min & f(\mathbf{x}) & \\
        \text{subject to} & g_i(\mathbf{x})\le 0, & i=1,2,\ldots,m \\
                          & h_j(\mathbf{x})=0, & j=1,2,\ldots,p \\
        & \mathbf{x}\in X,
    \end{array} 
\end{equation} 
where $f,g_i,h_j$ are functions defined on the set $X\subseteq\mathbb{R}^{n}$.
This is the ``usual'' optimization problem, and we refer to it as the
\textbf{primal} problem. The associated Lagrangian is
\[
        L(\mathbf{x},\pmb{\lambda},\pmb{\mu})=
        f(\mathbf{x})+\sum_{i=1}^{m} \lambda_ig_i(\mathbf{x})
        +\sum_{j=1}^{p} \mu_jh_j(\mathbf{x})
        \quad
        (\mathbf{x}\in
        X,\pmb{\lambda}\in\mathbb{R}^m_+,\pmb{\mu}\in\mathbb{R}^{p}).
\]
The \textbf{dual} objective function
$q:\mathbb{R}^m_+\times\mathbb{R}^{p}\rightarrow\mathbb{R}\cup\left\{-\infty\right\}$
is defined to be
\[
    q(\pmb{\lambda},\pmb{\mu})=\underset{\mathbf{x}\in
    X}{\min}L(\mathbf{x},\pmb{\lambda},\pmb{\mu})
\]
The domain of the dual objective function is
\[
    \text{dom}(q)=\left\{(\pmb{\lambda},\pmb{\mu})\in\mathbb{R}^{m}_+\times\mathbb{R}^{p}:q(\pmb{\lambda},\pmb{\mu})>-\infty\right\}.
\]
The \textbf{dual problem} is given by
\begin{equation*}\label{eq:dual}
    \tag{Dual}
    \begin{array}{c @{\quad} l}
        \max & q(\pmb{\lambda},\pmb{\mu}) \\
        \text{s.t.} & (\pmb{\lambda},\pmb{\mu})\in\text{dom}(q)
    \end{array} 
\end{equation*}

\newmdtheoremenv[style=defEnv]{concavity of q}[theorem]{Theorem}
\begin{concavity of q}
    Consider the primal problem~\eqref{eq:primal} with $f,g_i,h_j$ and $q$ the
    dual function defined in~\eqref{eq:dual}. Then
    \begin{enumerate}[label = (\alph*)]
        \item dom($q$) is a convex set
        \item $q$ is a concave function over dom($q$)
    \end{enumerate}
\end{concavity of q}

\section{Weak and Strong Duality}

\newmdtheoremenv[style=defEnv]{weak duality}[theorem]{(Weak Duality) Theorem}
\begin{weak duality}
    Consider the primal problem~\eqref{eq:primal} and its dual
    probelm~\eqref{eq:dual}. Then
    \[
        q^*\le f^*
    \]
    where $f^*,q^*$ are the primal and dual optimal values respectively.
\end{weak duality}

\newtheorem{weak duality example}[theorem]{Example}
\begin{weak duality example}
    Consider the problem
    \begin{equation*}
        \begin{array}{c @{\quad} l}
            \min & x_1^2-3x_2^2 \\
            \text{s.t.} & x_1=x_2^3
        \end{array} 
    \end{equation*}
    We can easily solve this to obtain $\mathbf{x}^*=(1,1)$ or $(-1,-1)$ so that
    $f^*=-2$.

    \medskip\noindent
    To solve the dual problem, we formulate the Lagrangian
    \[
        L(x_1,x_2,\lambda)=x_1^2-3x_2^2+\lambda(x_1-x_2^3)
    \]
    so that
    \[
        q(\lambda)
        =\underset{x_1,x_2}{\min} \;x_1^2+\lambda x_1-3x_2^2-\lambda x_2^3
        =-\infty
    \]
    since we can set $\lambda=\infty$ if $x_2>0$ or set $\lambda=-\infty$ if
    $x_2<0$.
\end{weak duality example}

\newmdtheoremenv[style=defEnv]{strong duality}[theorem]{Theorem}
\begin{strong duality}
    Consider the optimization problem $f^*$
    \begin{equation*}
        \begin{array}{c @{\quad} l @{\quad} l}
            \min & f(\mathbf{x}) & \\
            \text{s.t.} & g_i(\mathbf{x})\le 0, & i = 1,2,\ldots,m \\
                        & \mathbf{x}\in X
        \end{array} 
    \end{equation*}
    where $X$ is a convex set and $f, g_i$ are convex functions over $X$.
    Suppose that $\exists\mathbf{\mathbf{x}}\in X$ for which
    $g_i(\hat{\mathbf{x}})<0$. If this problem has a finite optimal value, then
    \begin{enumerate}
        \item the optimal value of the dual problem is obtained
        \item the primal and dual problems have the same optimal value,
            $f^*=q^*$.
    \end{enumerate}
\end{strong duality}

\newtheorem{strong duality example}[theorem]{Example}
\begin{strong duality example}
    Consider the problem
    \begin{equation*}
        \begin{array}{c @{\quad} l}
            \min & x_1^2-x_2 \\
            \text{s.t.} & x_2^2\le 0
        \end{array} 
    \end{equation*}
    We can deduce from $x_2^2\le 0$ that $x_2=0$, and since the minimal value of
    $x_1^2$ is 0, we can deduce that $x_1=0$ as well, so $\mathbf{x}^*=(0,0)$
    with $f^*=0$.

    \medskip\noindent
    To look at the dual problem, we construct the Lagrangian
    \[
        L(x_1,x_2,\lambda)=x_1^2-x_2+\lambda x_2^2
    \]
    thereby having
    \[
        q^*=\underset{x_1,x_2}{\min}\;x_1^2-x_2+\lambda x_2^2=
        \begin{cases}
            -\infty & \lambda=0 \\
            -\frac{1}{4\lambda} & \lambda>0
        \end{cases}
    \]
    and the duality problem yields $0$ with $\lambda=\infty$.
    Note that this is however never actually attained because Slator's condition
    is not fulfilled.
\end{strong duality example}

\newmdtheoremenv[style=defEnv]{complementary slackness condition}[theorem]
{(Complementary Slackness Conditions) Theorem}
\begin{complementary slackness condition}
    Consider the optimization problem
    \[
        f^*:=\min \left\{f(\mathbf{x}):g_i(\mathbf{x})\le
        0,i=1,2,\ldots,m,\mathbf{x}\in X\right\},
    \]
    and assume that $f^*=q^*$ where $q^*$ is the optimal value of the dual
    problem. Let $\mathbf{x}^*,\pmb{\lambda}^*$ be feasible solutions of the
    primal and dual problems. Then $\mathbf{x}^*$ and $\pmb{\lambda}^*$ are
    optimal solutions of the primal and dual problems iff
    \begin{enumerate}
        \item \label{csc1}
            $\mathbf{x}^*\in \underset{\mathbf{x}\in
            X}{\text{argmin}}\;L(\mathbf{x},\pmb{\lambda}^*)$
        \item $\lambda_i^*g_i(\mathbf{x}^*)=0,i=1,2,\ldots,m$.
    \end{enumerate}
\end{complementary slackness condition}
\underline{\textbf{Comments}}: By establishing e.g. strong duality condition,
the assumption of $f^*=g^*$ is automatically met, thereby the theorem could be
applied, e.g. find $\pmb{\lambda}^*$ first so that $\mathbf{x}^*$ could be
subsequently found by condition~\ref{csc1}.

\newmdtheoremenv[style=defEnv]{general strong duality theorem}[theorem]
{(General Strong Duality) Theorem}
\begin{general strong duality theorem}
    Consider the optimization problem
    \begin{equation*}
        \begin{array}{c @{\quad} l @{\quad} l}
            \min & f(\mathbf{x}) & \\
            \text{subject to} & g_i(\mathbf{x})\le 0, & i=1,2,\ldots,m \\
                              & h_j(\mathbf{x})\le 0, & j=1,2,\ldots,p \\
                              & s_k(\mathbf{x})=0, & k=1,2,\ldots,q \\
                              & \mathbf{x}\in X,
        \end{array} 
    \end{equation*} 
    where $X$ is a convex set and $f,g_i$ are convex functions over $X$. The
    functions $h_j,s_k$ are affine functions. Suppose that $\exists
    \hat{\mathbf{x}}\in\text{int}(X)$ 
    for which the \underline{Slater's conditions are met}.
    Then if the problem has a finite optimal value, then the optimal value of
    the dual problem
    \[
        q^*=\max
        \left\{q(\pmb{\lambda},\pmb{\eta},\pmb{\mu}):(\pmb{\lambda},\pmb{\eta},\pmb{\mu})\in\text{dom}(q)\right\}
    \]
    where
    \[
        q(\pmb{\lambda},\pmb{\eta},\pmb{\mu})=\underset{\mathbf{x}\in X}{\min}
        \left[f(\mathbf{x})+\sum_{i=1}^{m}
        \lambda_ig_i(\mathbf{x})+\sum_{j=1}^{p}\eta_jh_j(\mathbf{x})+\sum_{k=1}^{q}\mu_ks_k(\mathbf{x})\right]
    \]
    is attained, and $f^*=q^*$.
\end{general strong duality theorem}

See the 3 examples on notes for applications of duality concept.



\end{document}
